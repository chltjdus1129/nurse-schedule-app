import streamlit as st
import pandas as pd
import math
import os
import requests

from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.ensemble import IsolationForest
import altair as alt

# -------------------------------
# Hugging Face Router ì„¤ì •
# -------------------------------
HF_API_URL = "https://router.huggingface.co/v1/chat/completions"
HF_MODEL = "meta-llama/Llama-3.1-8B-Instruct"
HF_API_TOKEN = os.getenv("HF_API_TOKEN")

# -------------------------------
# ê¸°ë³¸ ë§¤í•‘ / ìƒìˆ˜
# -------------------------------
LEVEL_MAP = {0: "novice", 1: "competence", 2: "leader"}
LEVEL_KO = {0: "ì €ì—°ì°¨", 1: "ì¤‘ê°„ì—°ì°¨", 2: "ê³ ì—°ì°¨"}

SHIFT_MAP = {
    0: "D",    # day
    1: "E",    # eve
    2: "N",    # night
    3: "9D",   # 9ì‹œ day
    4: "OFF",
}

# ë‚ ì§œë³„ ê¸°ì¤€ ì¸ë ¥
SHIFT_REQUIREMENTS = {
    0: 6,  # D
    1: 6,  # E
    2: 5,  # N
    3: 1,  # 9D
}

# ê·¼ë¬´ ì‹œì‘/ë ì‹œê°„ (ì‹œê°„ ë‹¨ìœ„, ë°¤ ê·¼ë¬´ëŠ” 24+ ë¡œ í‘œí˜„)
SHIFT_START_HOUR = {
    0: 6.5,   # D: 06:30
    1: 14.5,  # E: 14:30
    2: 22.5,  # N: 22:30
    3: 9.0,   # 9D: 09:00
}

SHIFT_END_HOUR = {
    0: 15.0,  # D: 15:00
    1: 23.0,  # E: 23:00
    2: 31.0,  # N: 07:00 (ë‹¤ìŒë‚  7ì‹œ = 24+7)
    3: 17.5,  # 9D: 17:30
}

RISK_SCORE = {
    "no": 0,
    "low": 1,
    "moderate": 2,
    "critical": 3,
}

RISK_LABEL_KO = {
    "critical": "ê³ ìœ„í—˜",
    "moderate": "ì¤‘ë“±ë„ ìœ„í—˜",
    "low": "ì €ìœ„í—˜",
    "no": "ì •ìƒ",
    "no_preference": "ì„ í˜¸ ì—†ìŒ",
    "no_request": "ìš”ì²­ ì—†ìŒ",
}


def risk_to_ko(v: str) -> str:
    if pd.isna(v):
        return ""
    return RISK_LABEL_KO.get(str(v), str(v))


# -------------------------------
# ê³µí†µ ìœ í‹¸ í•¨ìˆ˜
# -------------------------------
def get_date_columns(df: pd.DataFrame):
    """nurse_id, nurse_name, level ì„ ì œì™¸í•œ ë‚ ì§œ ì»¬ëŸ¼ ëª©ë¡"""
    return [c for c in df.columns if c not in ["nurse_id", "nurse_name", "level"]]


def longest_streak(values, is_valid):
    """values ë¦¬ìŠ¤íŠ¸ì—ì„œ is_valid(x)==True ì¸ ê°’ë“¤ì˜ ìµœì¥ ì—°ì† ê¸¸ì´"""
    max_run = 0
    current = 0
    for v in values:
        if pd.isna(v):
            current = 0
            continue
        if is_valid(int(v)):
            current += 1
            max_run = max(max_run, current)
        else:
            current = 0
    return max_run


# -------------------------------
# ìœ„í—˜ë„ íŒì • í•¨ìˆ˜ë“¤
# -------------------------------
def work_streak_risk(n: int) -> str:
    if n >= 6:
        return "critical"
    elif n == 5:
        return "moderate"
    elif n == 4:
        return "low"
    else:
        return "no"


def night_streak_risk(n: int) -> str:
    if n >= 5:
        return "critical"
    elif n == 4:
        return "moderate"
    elif n == 3:
        return "low"
    else:
        return "no"


def total_off_days_risk(off_days: int) -> str:
    if off_days <= 8:
        return "critical"
    elif off_days == 9:
        return "moderate"
    elif 10 <= off_days <= 12:
        return "low"
    else:
        return "no"


def total_night_days_risk(n_nights: int) -> str:
    if n_nights >= 7:
        return "critical"
    elif n_nights == 6:
        return "low"
    else:
        return "no"


def ed_quick_return_risk(crit_cnt: int, mod_cnt: int) -> str:
    if crit_cnt > 0:
        return "critical"
    elif mod_cnt > 0:
        return "moderate"
    else:
        return "no"


def n_quick_return_risk(crit_cnt: int, mod_cnt: int, low_cnt: int) -> str:
    if crit_cnt > 0:
        return "critical"
    elif mod_cnt > 0:
        return "moderate"
    elif low_cnt > 0:
        return "low"
    else:
        return "no"


def staffing_risk_label(shortage: int) -> str:
    if shortage <= 0:
        return "no"
    elif shortage == 1:
        return "moderate"
    else:
        return "critical"


def overall_staffing_risk_day(risks_for_day):
    if "critical" in risks_for_day:
        return "critical"
    elif "moderate" in risks_for_day:
        return "moderate"
    elif "low" in risks_for_day:
        return "low"
    else:
        return "no"


def off_interval_risk(min_rest_hours):
    if min_rest_hours is None or (isinstance(min_rest_hours, float) and math.isnan(min_rest_hours)):
        return "no"
    if min_rest_hours < 11:
        return "critical"
    elif 11 <= min_rest_hours < 16:
        return "low"
    else:
        return "no"


def ratio_risk(r):
    if r is None or pd.isna(r):
        return "no"
    if r > 1.4:
        return "critical"
    elif r > 1.2:
        return "moderate"
    elif r >= 1.0:
        return "low"
    else:
        return "no"


# -------------------------------
# Quick return ìŠ¤ìº”
# -------------------------------
def scan_quick_returns(values):
    """
    ED quick return:
      critical: ED(1,0), E9D(1,3)
      moderate: EOD(1,4,0), EO9D(1,4,3)

    N quick return (ê³µì£¼ë‹˜ ì •ì˜ ë°˜ì˜):
      critical: ND(2,0), NOD(2,4,0), N9D(2,3), NO9D(2,4,3), NE(2,1)
      moderate: NOE(2,4,1)
    """
    ed_crit = ed_mod = 0
    n_crit = n_mod = n_low = 0

    for i, v in enumerate(values):
        if pd.isna(v):
            continue
        v = int(v)

        # --- ED quick return ---
        if v == 1:  # E
            # í•œ ì¹¸ ë’¤: D(0) ë˜ëŠ” 9D(3) â†’ critical
            if i + 1 < len(values) and not pd.isna(values[i + 1]):
                v1 = int(values[i + 1])
                if v1 in (0, 3):
                    ed_crit += 1
            # ë‘ ì¹¸ ë’¤: E-O-D / E-O-9D â†’ moderate
            if i + 2 < len(values) and not pd.isna(values[i + 1]) and not pd.isna(values[i + 2]):
                v1 = int(values[i + 1])
                v2 = int(values[i + 2])
                if v1 == 4 and v2 in (0, 3):
                    ed_mod += 1

        # --- N quick return ---
        if v == 2:  # N
            # í•œ ì¹¸ ë’¤: D(0), E(1), 9D(3) â†’ ëª¨ë‘ critical
            if i + 1 < len(values) and not pd.isna(values[i + 1]):
                v1 = int(values[i + 1])
                if v1 in (0, 1, 3):
                    n_crit += 1

            # ë‘ ì¹¸ ë’¤: N-O-D / N-O-9D / N-O-E
            if i + 2 < len(values) and not pd.isna(values[i + 1]) and not pd.isna(values[i + 2]):
                v1 = int(values[i + 1])
                v2 = int(values[i + 2])
                if v1 == 4:  # ì¤‘ê°„ì— OFF
                    if v2 in (0, 3):    # NOD, NO9D
                        n_crit += 1
                    elif v2 == 1:       # NOE
                        n_mod += 1

    return ed_crit, ed_mod, n_crit, n_mod, n_low


# -------------------------------
# Staffing ë¶„ì„
# -------------------------------
def compute_staffing_features(schedule_df: pd.DataFrame) -> pd.DataFrame:
    date_cols = get_date_columns(schedule_df)
    numeric = schedule_df[date_cols].apply(pd.to_numeric, errors="coerce")

    rows = []
    for col in date_cols:
        col_values = numeric[col]
        row = {"date": col}
        day_risks = []

        for shift_code, required in SHIFT_REQUIREMENTS.items():
            count = (col_values == shift_code).sum()
            shortage = required - count
            shortage_for_display = max(shortage, 0)
            risk = staffing_risk_label(shortage)

            label = SHIFT_MAP[shift_code]
            row[f"{label}_count"] = int(count)
            row[f"{label}_required"] = required
            row[f"{label}_shortage"] = int(shortage_for_display)
            row[f"{label}_risk"] = risk
            day_risks.append(risk)

        row["overall_staffing_risk"] = overall_staffing_risk_day(day_risks)
        rows.append(row)

    df = pd.DataFrame(rows)
    # ë‚ ì§œë¥¼ datetime ìœ¼ë¡œ í•œ ë²ˆ ë³€í™˜í•´ë‘ê¸° (ê·¸ë˜í”„ìš©)
    try:
        df["date"] = pd.to_datetime(df["date"])
    except Exception:
        pass
    return df


# -------------------------------
# ìµœì†Œ íœ´ì‹ì‹œê°„ ê³„ì‚°
# -------------------------------
def compute_min_off_interval(values):
    """ì—°ì† ê·¼ë¬´ë“¤ ì‚¬ì´ì˜ ìµœì†Œ íœ´ì‹ì‹œê°„(ì‹œê°„ ë‹¨ìœ„) ê³„ì‚°"""
    work_indices = [
        idx for idx, v in enumerate(values)
        if not pd.isna(v) and int(v) in (0, 1, 2, 3)
    ]
    if len(work_indices) <= 1:
        return None

    rests = []
    for k in range(len(work_indices) - 1):
        i = work_indices[k]
        j = work_indices[k + 1]
        s1 = int(values[i])
        s2 = int(values[j])

        end_time = SHIFT_END_HOUR.get(s1)
        start_time = SHIFT_START_HOUR.get(s2)
        if end_time is None or start_time is None:
            continue

        rest = (j - i) * 24 + start_time - end_time
        rests.append(rest)

    if not rests:
        return None
    return min(rests)


# -------------------------------
# ì›”ê°„ feature ê³„ì‚° (ìœ„í—˜ë„ + ê³µì •ì„± ê¸°ë³¸)
# -------------------------------
def compute_monthly_features(schedule_df: pd.DataFrame) -> pd.DataFrame:
    date_cols = get_date_columns(schedule_df)
    numeric = schedule_df[date_cols].apply(pd.to_numeric, errors="coerce")

    # ê¸°ë³¸ ì§‘ê³„
    total_off_days = (numeric == 4).sum(axis=1)
    total_night_days = (numeric == 2).sum(axis=1)
    total_working_days = numeric.isin([0, 1, 2, 3]).sum(axis=1)

    working_streaks = []
    night_streaks = []
    ed_crit_list = []
    ed_mod_list = []
    n_crit_list = []
    n_mod_list = []
    n_low_list = []
    min_rest_list = []

    for _, row in numeric.iterrows():
        values = row.values.tolist()

        max_work_streak = longest_streak(values, lambda x: x in (0, 1, 2, 3))
        max_night_streak = longest_streak(values, lambda x: x == 2)
        working_streaks.append(max_work_streak)
        night_streaks.append(max_night_streak)

        ed_c, ed_m, n_c, n_m, n_l = scan_quick_returns(values)
        ed_crit_list.append(ed_c)
        ed_mod_list.append(ed_m)
        n_crit_list.append(n_c)
        n_mod_list.append(n_m)
        n_low_list.append(n_l)

        min_rest = compute_min_off_interval(values)
        min_rest_list.append(min_rest)

    # ê²°ê³¼ í…Œì´ë¸” êµ¬ì„±
    result = schedule_df[["nurse_id", "nurse_name", "level"]].copy()
    result["level_name"] = result["level"].map(LEVEL_MAP)

    result["total_off_days"] = total_off_days
    result["total_night_days"] = total_night_days
    result["total_working_days"] = total_working_days

    result["total_off_days_risk"] = result["total_off_days"].apply(total_off_days_risk)
    result["total_night_days_risk"] = result["total_night_days"].apply(total_night_days_risk)

    result["consecutive_working_days"] = working_streaks
    result["consecutive_working_days_risk"] = [
        work_streak_risk(n) for n in working_streaks
    ]

    result["consecutive_night_shifts"] = night_streaks
    result["consecutive_night_shifts_risk"] = [
        night_streak_risk(n) for n in night_streaks
    ]

    result["min_off_interval_hours"] = min_rest_list
    result["min_off_interval_risk"] = result["min_off_interval_hours"].apply(
        off_interval_risk
    )

    # ED / N quick return
    result["ED_quick_return_critical"] = ed_crit_list
    result["ED_quick_return_moderate"] = ed_mod_list
    result["ED_quick_return_total"] = (
        result["ED_quick_return_critical"] + result["ED_quick_return_moderate"]
    )
    result["ED_quick_return_risk"] = [
        ed_quick_return_risk(c, m) for c, m in zip(ed_crit_list, ed_mod_list)
    ]

    result["N_quick_return_critical"] = n_crit_list
    result["N_quick_return_moderate"] = n_mod_list
    result["N_quick_return_low"] = n_low_list
    result["N_quick_return_total"] = (
        result["N_quick_return_critical"]
        + result["N_quick_return_moderate"]
        + result["N_quick_return_low"]
    )
    result["N_quick_return_risk"] = [
        n_quick_return_risk(c, m, l)
        for c, m, l in zip(n_crit_list, n_mod_list, n_low_list)
    ]

    # ì—°ì°¨ ëŒ€ë¹„ ê·¼ë¬´/ì•¼ê°„ ë¹„ìœ¨
    result["level_night_ratio"] = pd.NA
    result["level_workingdays_ratio"] = pd.NA

    for lvl in result["level"].unique():
        mask_self = result["level"] == lvl
        mask_others = result["level"] != lvl
        if mask_others.sum() == 0:
            continue

        other_n_mean = result.loc[mask_others, "total_night_days"].mean()
        other_w_mean = result.loc[mask_others, "total_working_days"].mean()

        if other_n_mean and other_n_mean > 0:
            result.loc[mask_self, "level_night_ratio"] = (
                result.loc[mask_self, "total_night_days"] / other_n_mean
            )
        if other_w_mean and other_w_mean > 0:
            result.loc[mask_self, "level_workingdays_ratio"] = (
                result.loc[mask_self, "total_working_days"] / other_w_mean
            )

    result["level_night_ratio_risk"] = result["level_night_ratio"].apply(ratio_risk)
    result["level_workingdays_ratio_risk"] = result["level_workingdays_ratio"].apply(
        ratio_risk
    )

    return result


# -------------------------------
# Swing íŒ¨í„´ íƒì§€
# -------------------------------
def has_swing_pattern(values):
    """
    ì—°ì† ê·¼ë¬´(OFF ì—†ì´ 0~3) êµ¬ê°„ì—ì„œ
    ê·¼ë¬´ ì½”ë“œê°€ ë°”ë€ŒëŠ” ì§€ì ì´ 1ë²ˆì´ë¼ë„ ìˆìœ¼ë©´ swing íŒ¨í„´ ìˆë‹¤ê³  ë´„.
    """
    prev = None
    for v in values:
        if pd.isna(v):
            prev = None
            continue
        v_int = int(v)
        if v_int in (0, 1, 2, 3):
            if prev is not None and prev in (0, 1, 2, 3) and prev != v_int:
                return True
            prev = v_int
        else:
            prev = None
    return False


# -------------------------------
# ì„ í˜¸ê·¼ë¬´ ê¸°ë°˜ ê³µì •ì„± feature (ì°¸ê³  ì½”ë“œ ë²„ì „ ë°˜ì˜)
# -------------------------------
def compute_preference_features(
    base_df: pd.DataFrame,
    schedule_df: pd.DataFrame,
    pref_df: pd.DataFrame,
) -> pd.DataFrame:
    """
    base_df : compute_monthly_features() ê²°ê³¼
    schedule_df : ì‹¤ì œ ê·¼ë¬´í‘œ (ì½”ë“œ 0~4)
    pref_df : ì„ í˜¸ê·¼ë¬´í‘œ (ê°™ì€ nurse_id + ë‚ ì§œ ì»¬ëŸ¼, ë§ˆì§€ë§‰ì— preferred_swing_types / preferred_shift_types)
    """
    base = base_df.copy()
    base = base.set_index("nurse_id", drop=False)

    # ë‚ ì§œ ì»¬ëŸ¼ ì •ë ¬
    date_cols_sched = get_date_columns(schedule_df)
    date_cols = [c for c in date_cols_sched if c in pref_df.columns]

    # ìˆ˜ì¹˜í˜•ìœ¼ë¡œ ë³€í™˜
    sched_numeric = (
        schedule_df.set_index("nurse_id")[date_cols]
        .apply(pd.to_numeric, errors="coerce")
    )
    pref_numeric = (
        pref_df.set_index("nurse_id")[date_cols]
        .apply(pd.to_numeric, errors="coerce")
    )

    # ì„ í˜¸ shift íƒ€ì… (ì˜ˆ: 0=day, 1=eve ë“±, nurse ë‹¨ìœ„ 1ê°œ ê°’)
    if "preferred_shift_types" in pref_df.columns:
        pref_shift_series = pd.to_numeric(
            pref_df.set_index("nurse_id")["preferred_shift_types"],
            errors="coerce",
        )
    else:
        pref_shift_series = pd.Series(dtype="float64")

    # ë³€í˜•ê·¼ë¬´(swing) ì„ í˜¸ ì—¬ë¶€ (* ë“± í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ True)
    if "preferred_swing_types" in pref_df.columns:
        swing_raw = pref_df.set_index("nurse_id")["preferred_swing_types"]
        swing_flag_series = swing_raw.notna() & (
            swing_raw.astype(str).str.strip() != ""
        )
    else:
        swing_flag_series = pd.Series(
            False,
            index=pref_df.set_index("nurse_id").index,
        )

    # ê²°ê³¼ ì €ì¥ìš© dict
    shift_type_code_dict = {}
    shift_ratio_dict = {}
    shift_req_dict = {}
    shift_match_dict = {}

    duty_req_dict = {}
    duty_match_dict = {}
    duty_ratio_dict = {}

    swing_flag_dict = {}
    swing_pattern_dict = {}

    # ê°„í˜¸ì‚¬ë³„ë¡œ ì„ í˜¸ ë°˜ì˜ ê³„ì‚°
    for nid in base.index:
        # ê¸°ë³¸ ê°’ ì´ˆê¸°í™”
        shift_type_code = math.nan
        shift_ratio = math.nan
        shift_req = 0
        shift_match = 0

        duty_req = 0
        duty_match = 0
        duty_ratio = math.nan

        swing_flag = False
        swing_has_pattern = False

        # nurse_idê°€ ë‘ DFì— ëª¨ë‘ ì¡´ì¬í•˜ëŠ” ê²½ìš°ì—ë§Œ ê³„ì‚°
        if (nid in sched_numeric.index) and (nid in pref_numeric.index):
            sched_row = sched_numeric.loc[nid]
            pref_row = pref_numeric.loc[nid]

            total_working = (
                base.loc[nid, "total_working_days"]
                if "total_working_days" in base.columns
                else sched_row.isin([0, 1, 2, 3]).sum()
            )

            # --- (1) preferred_shift_types : ì „ì²´ ì„ í˜¸ ê·¼ë¬´ íƒ€ì… ë°˜ì˜ë¥  ---
            if nid in pref_shift_series.index:
                p_code = pref_shift_series.loc[nid]
                shift_type_code = p_code
                if not pd.isna(p_code) and total_working and total_working > 0:
                    match_days = (sched_row == p_code).sum()
                    shift_match = int(match_days)
                    shift_req = int(total_working)
                    shift_ratio = match_days / float(total_working)

            # --- (2) preferred_duty_choice_types : ë‚ ì§œë³„ í¬ë§ ë“€í‹° ë°˜ì˜ë¥  ---
            for col in date_cols:
                p_val = pref_row[col]
                s_val = sched_row[col]
                if not pd.isna(p_val):
                    duty_req += 1
                    if not pd.isna(s_val) and int(p_val) == int(s_val):
                        duty_match += 1
            if duty_req > 0:
                duty_ratio = duty_match / float(duty_req)

            # --- (3) preferred_swing_types : swing ì„ í˜¸ + ì‹¤ì œ swing íŒ¨í„´ ---
            if nid in swing_flag_series.index:
                swing_flag = bool(swing_flag_series.loc[nid])
            # ìŠ¤ì¼€ì¤„ì—ì„œ swing íŒ¨í„´ ì¡´ì¬ ì—¬ë¶€
            swing_has_pattern = has_swing_pattern(sched_row.values.tolist())

        # dictì— ì €ì¥
        shift_type_code_dict[nid] = shift_type_code
        shift_ratio_dict[nid] = shift_ratio
        shift_req_dict[nid] = shift_req
        shift_match_dict[nid] = shift_match

        duty_req_dict[nid] = duty_req
        duty_match_dict[nid] = duty_match
        duty_ratio_dict[nid] = duty_ratio

        swing_flag_dict[nid] = swing_flag
        swing_pattern_dict[nid] = swing_has_pattern

    # --- (1) ì„ í˜¸ ê·¼ë¬´íƒ€ì… ë°˜ì˜ë¥ ì˜ ë¶„ìœ„ìˆ˜ ê¸°ë°˜ risk ---
    shift_ratio_series = pd.Series(shift_ratio_dict)
    valid_shift = shift_ratio_series.dropna()
    if len(valid_shift) > 0:
        q10 = valid_shift.quantile(0.10)
        q25 = valid_shift.quantile(0.25)
    else:
        q10 = q25 = None

    shift_risk_dict = {}
    for nid, r in shift_ratio_dict.items():
        code = shift_type_code_dict.get(nid, math.nan)
        if (
            code is None
            or (isinstance(code, float) and math.isnan(code))
            or q10 is None
        ):
            shift_risk = "no_preference"
        else:
            if r < q10:
                shift_risk = "critical"
            elif r < q25:
                shift_risk = "moderate"
            else:
                shift_risk = "low"
        shift_risk_dict[nid] = shift_risk

    # --- (2) í¬ë§ ë“€í‹° ë°˜ì˜ë¥  ê¸°ë°˜ risk ---
    duty_risk_dict = {}
    for nid, r in duty_ratio_dict.items():
        req = duty_req_dict.get(nid, 0)
        if req == 0 or pd.isna(r):
            duty_risk = "no_request"
        else:
            if r <= 0.75:
                duty_risk = "critical"
            elif r <= 0.875:
                duty_risk = "moderate"
            else:
                duty_risk = "low"
        duty_risk_dict[nid] = duty_risk

    # --- (3) swing ì„ í˜¸ ë°˜ì˜ ì—¬ë¶€ risk ---
    swing_risk_dict = {}
    for nid in base.index:
        flag = swing_flag_dict.get(nid, False)
        has_pattern = swing_pattern_dict.get(nid, False)
        if not flag:
            swing_risk = "no"
        else:
            if has_pattern:
                swing_risk = "no"   # ì„ í˜¸ ë°˜ì˜ ì˜ ë¨ â†’ risk ì—†ìŒ
            else:
                swing_risk = "low"  # ì„ í˜¸ ë°˜ì˜ ì•ˆ ë¨ â†’ low risk ì •ë„
        swing_risk_dict[nid] = swing_risk

    # base DFì— ì»¬ëŸ¼ ì¶”ê°€
    base["preferred_shift_type_code"] = pd.Series(shift_type_code_dict)
    base["preferred_shift_ratio"] = pd.Series(shift_ratio_dict)
    base["preferred_shift_ratio_risk"] = pd.Series(shift_risk_dict)
    base["preferred_shift_total"] = pd.Series(shift_req_dict)
    base["preferred_shift_matched"] = pd.Series(shift_match_dict)

    base["preferred_duty_requests"] = pd.Series(duty_req_dict)
    base["preferred_duty_matched"] = pd.Series(duty_match_dict)
    base["preferred_duty_choice_ratio"] = pd.Series(duty_ratio_dict)
    base["preferred_duty_choice_risk"] = pd.Series(duty_risk_dict)

    base["preferred_swing_flag"] = pd.Series(swing_flag_dict)
    base["preferred_swing_has_pattern"] = pd.Series(swing_pattern_dict)
    base["preferred_swing_risk"] = pd.Series(swing_risk_dict)

    return base.reset_index(drop=True)


# -------------------------------
# í´ëŸ¬ìŠ¤í„°ë§ + ì´ìƒì¹˜ íƒì§€
# -------------------------------
def run_clustering_and_outlier(fairness_df: pd.DataFrame, n_clusters: int = 3, contamination: float = 0.1):
    df = fairness_df.copy()

    # ì‚¬ìš©í•  feature(ìˆ«ìí˜•) ì„ ì •
    feature_cols = [
        "total_off_days",
        "total_night_days",
        "total_working_days",
        "consecutive_working_days",
        "consecutive_night_shifts",
        "min_off_interval_hours",
        "ED_quick_return_total",
        "N_quick_return_total",
        "level_night_ratio",
        "level_workingdays_ratio",
        "preferred_shift_ratio",
        "preferred_duty_choice_ratio",
    ]

    # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì‚¬ìš©
    feature_cols = [c for c in feature_cols if c in df.columns]

    if len(feature_cols) == 0 or len(df) < 3:
        df["cluster"] = 0
        df["cluster_name"] = "Cluster A"
        df["is_outlier"] = "normal"
        return df

    X = df[feature_cols].astype(float).copy()

    # ê²°ì¸¡ì¹˜ëŠ” ê° ì»¬ëŸ¼ì˜ ì¤‘ì•™ê°’ìœ¼ë¡œ ì±„ìš°ê¸°
    for c in feature_cols:
        med = X[c].median()
        X[c] = X[c].fillna(med)

    # í‘œì¤€í™”
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # KMeans í´ëŸ¬ìŠ¤í„°ë§
    k = min(n_clusters, len(df))  # ê°„í˜¸ì‚¬ ìˆ˜ë³´ë‹¤ í° K ë°©ì§€
    if k < 2:
        k = 2
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    clusters = kmeans.fit_predict(X_scaled)
    df["cluster"] = clusters
    df["cluster_name"] = df["cluster"].apply(lambda x: f"Cluster {chr(ord('A') + int(x))}")

    # IsolationForest ì´ìƒì¹˜ íƒì§€
    try:
        iso = IsolationForest(contamination=contamination, random_state=42)
        out_pred = iso.fit_predict(X_scaled)  # -1: outlier, 1: normal
        df["anomaly_score_raw"] = out_pred
        df["is_outlier"] = df["anomaly_score_raw"].apply(lambda v: "outlier" if v == -1 else "normal")
    except Exception:
        df["anomaly_score_raw"] = 1
        df["is_outlier"] = "normal"

    return df


# -------------------------------
# LLM í˜¸ì¶œ (Hugging Face Router)
# -------------------------------
def call_llm(system_prompt: str, user_prompt: str) -> str:
    """
    Hugging Face Routerë¥¼ í†µí•´ Llama-3.1-8B-Instructë¥¼ í˜¸ì¶œí•˜ëŠ” í•¨ìˆ˜.
    system_prompt, user_promptëŠ” ëª¨ë‘ í•œêµ­ì–´ ë¬¸ìì—´ë¡œ ë„˜ê¹ë‹ˆë‹¤.
    """
    if not HF_API_TOKEN:
        return (
            "âŒ HF_API_TOKENì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n"
            "CMD ì°½ì—ì„œ ë¨¼ì € ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•´ ì£¼ì„¸ìš”:\n"
            "  set HF_API_TOKEN=hf_ë¡œ_ì‹œì‘í•˜ëŠ”_í† í°ê°’"
        )

    headers = {
        "Authorization": f"Bearer {HF_API_TOKEN}",
        "Content-Type": "application/json",
    }

    payload = {
        "model": HF_MODEL,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ],
        "max_tokens": 500,
        "temperature": 0.3,
    }

    try:
        res = requests.post(HF_API_URL, headers=headers, json=payload, timeout=60)
        res.raise_for_status()
        data = res.json()
        return data["choices"][0]["message"]["content"].strip()
    except Exception as e:
        return f"[ì˜¤ë¥˜] LLM í˜¸ì¶œ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"


# -------------------------------
# Streamlit ì•± ê¸°ë³¸ ì„¤ì • & ì„¸ì…˜ ìƒíƒœ
# -------------------------------
st.set_page_config(
    page_title="Nurse Schedule AI (ë¡œì»¬+HF)",
    layout="wide",
)

if "schedule_df" not in st.session_state:
    st.session_state.schedule_df = None
    st.session_state.monthly_features_df = None
    st.session_state.staffing_df = None
    st.session_state.pref_df = None
    st.session_state.fairness_pref_df = None
    st.session_state.clustered_df = None
    st.session_state.chat_history = []

st.title("ğŸ©º ê°„í˜¸ì‚¬ ìŠ¤ì¼€ì¤„ ì¸í…”ë¦¬ì „ìŠ¤ (Nurse Schedule Intelligence)")

st.markdown(
    """
ì´ ì•±ì€ **ê°„í˜¸ì‚¬ ê·¼ë¬´í‘œ(ìŠ¤ì¼€ì¤„)**ì™€ **ì„ í˜¸ê·¼ë¬´í‘œ(pref)**ë¥¼ ì—…ë¡œë“œí•˜ë©´,

1. AIë¥¼ í†µí•œ ì±—ë´‡ Q&A  
2. ë‚ ì§œë³„ ì¸ë ¥ ê¸°ì¤€ ì¶©ì¡± ì—¬ë¶€ì™€ í™˜ì ì•ˆì „ ìœ„í—˜ë„  
3. ê°œë³„ ê°„í˜¸ì‚¬ ê³µì •ì„±  
4. ìŠ¤ì¼€ì¤„ íŒ¨í„´ ìë™ ë¶„ë¥˜ì™€ LLM ê¸°ë°˜ ìë™ í•´ì„ ë¦¬í¬íŠ¸     

ë¥¼ ë³´ì—¬ì£¼ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.
"""
)

st.write("---")

tab_schedule, tab_chat, tab_risk, tab_fairness, tab_report = st.tabs(
    ["ğŸ“‚ Schedule", "ğŸ’¬ Chatbot", "ğŸ“Š Risk Dashboard", "âš–ï¸ Fairness Dashboard", "ğŸ§  AI Report"]
)

# ============================================================
# 1. Schedule íƒ­ (ì—…ë¡œë“œ + ë¯¸ë¦¬ë³´ê¸°)
# ============================================================
with tab_schedule:
    st.subheader("ğŸ“‚ ê·¼ë¬´í‘œ / ì„ í˜¸ê·¼ë¬´í‘œ ì—…ë¡œë“œ")

    col1, col2 = st.columns(2)

    with col1:
        schedule_file = st.file_uploader(
            "1ï¸âƒ£ ê·¼ë¬´ ìŠ¤ì¼€ì¤„ ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ (í•„ìˆ˜)",
            type=["xlsx", "xls"],
            key="schedule_file_uploader",
        )

    with col2:
        pref_file = st.file_uploader(
            "2ï¸âƒ£ ì„ í˜¸ê·¼ë¬´í‘œ ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ (ì„ íƒ)",
            type=["xlsx", "xls"],
            key="pref_file_uploader",
        )

    # ì—…ë¡œë“œ í›„ ì¦‰ì‹œ ë¶„ì„
    if schedule_file is not None:
        try:
            schedule_df = pd.read_excel(schedule_file)
            st.session_state.schedule_df = schedule_df
            st.session_state.monthly_features_df = compute_monthly_features(schedule_df)
            st.session_state.staffing_df = compute_staffing_features(schedule_df)
        except Exception as e:
            st.error(f"ê·¼ë¬´í‘œ ì—‘ì…€ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            st.stop()

        st.subheader("ğŸ“„ ì›ë³¸ ê·¼ë¬´í‘œ ë¯¸ë¦¬ë³´ê¸°")
        st.caption("â€» nurse_id / nurse_name / level ì´í›„ì— ë‚ ì§œë³„ ê·¼ë¬´ì½”ë“œ(0=D,1=E,2=N,3=9D,4=OFF)ê°€ ì™€ì•¼ í•©ë‹ˆë‹¤.")
        st.dataframe(schedule_df.head(15), use_container_width=True)

    if (pref_file is not None) and (st.session_state.schedule_df is not None):
        try:
            pref_df = pd.read_excel(pref_file)
            st.session_state.pref_df = pref_df

            fairness_pref_df = compute_preference_features(
                st.session_state.monthly_features_df,
                st.session_state.schedule_df,
                pref_df,
            )
            st.session_state.fairness_pref_df = fairness_pref_df

            # í´ëŸ¬ìŠ¤í„°ë§
            st.sidebar.markdown("### âš™ï¸ í´ëŸ¬ìŠ¤í„°ë§ / ì´ìƒì¹˜ íƒì§€ ì„¤ì •")
            k_for_cluster = st.sidebar.slider("í´ëŸ¬ìŠ¤í„° ê°œìˆ˜ (KMeans)", 2, 5, 3, 1)
            contamination_rate = st.sidebar.slider("ì´ìƒì¹˜ ë¹„ìœ¨ (IsolationForest)", 0.05, 0.3, 0.1, 0.05)

            clustered_df = run_clustering_and_outlier(
                fairness_pref_df,
                n_clusters=k_for_cluster,
                contamination=contamination_rate,
            )
            st.session_state.clustered_df = clustered_df
        except Exception as e:
            st.error(f"ì„ í˜¸ê·¼ë¬´í‘œ ì—‘ì…€ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            st.stop()

        st.subheader("ğŸ“„ ì„ í˜¸ê·¼ë¬´í‘œ ë¯¸ë¦¬ë³´ê¸°")
        st.caption(
            "â€» ê·¼ë¬´í‘œì™€ ë™ì¼í•œ nurse_id / nurse_name / level / ë‚ ì§œ ì»¬ëŸ¼ êµ¬ì¡°ë¥¼ ê°€ì§€ë©°, "
            "`preferred_swing_types`, `preferred_shift_types` ì»¬ëŸ¼ì´ ë’¤ì— ì¶”ê°€ëœ í˜•íƒœì—¬ì•¼ í•©ë‹ˆë‹¤."
        )
        st.dataframe(pref_df.head(15), use_container_width=True)

    if st.session_state.schedule_df is None:
        st.info("ë¨¼ì € **ê·¼ë¬´ ìŠ¤ì¼€ì¤„ ì—‘ì…€ íŒŒì¼**ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")


# ê³µí†µìœ¼ë¡œ ì‚¬ìš©í•  ë°ì´í„° ë‹¨ì¶• ë³€ìˆ˜
schedule_df = st.session_state.schedule_df
monthly_features_df = st.session_state.monthly_features_df
staffing_df = st.session_state.staffing_df
pref_df = st.session_state.pref_df
clustered_df = st.session_state.clustered_df

# ============================================================
# 2. Chatbot íƒ­
# ============================================================
with tab_chat:
    st.subheader("ğŸ’¬ AI ì±—ë´‡ (ê°„í˜¸ì‚¬ë³„ + ë¶€ì„œ ì „ì²´ Q&A)")

    if clustered_df is None:
        st.info("ì±—ë´‡ì„ ì‚¬ìš©í•˜ë ¤ë©´ **Schedule íƒ­ì—ì„œ ê·¼ë¬´í‘œì™€ ì„ í˜¸ê·¼ë¬´í‘œë¥¼ ëª¨ë‘ ì—…ë¡œë“œ**í•´ ì£¼ì„¸ìš”.")
    else:
        # ë¶€ì„œ ì „ì²´ ìš”ì•½ (ë¹„êµ ì§ˆë¬¸ìš©)
        summary_lines = []
        for _, r in clustered_df.iterrows():
            summary_lines.append(
                f"- {r['nurse_id']} {r['nurse_name']} "
                f"(ì—°ì°¨={LEVEL_KO.get(r['level'], r['level'])}, "
                f"cluster={r['cluster_name']}, outlier={r['is_outlier']}, "
                f"ì´ê·¼ë¬´ì¼={r['total_working_days']}, Nê·¼ë¬´={r['total_night_days']}, "
                f"ì—°ì†ê·¼ë¬´={r['consecutive_working_days']}, ì—°ì†N={r['consecutive_night_shifts']}, "
                f"ED QR={r['ED_quick_return_total']}, N QR={r['N_quick_return_total']}, "
                f"í¬ë§ê·¼ë¬´ ë°˜ì˜ë¥ ={r['preferred_shift_ratio']}, "
                f"ì„ í˜¸ê·¼íƒœ ë°˜ì˜ë¥ ={r['preferred_duty_choice_ratio']}, "
                f"swing ìœ„í—˜ë„={r['preferred_swing_risk']})"
            )
        all_nurses_summary = "\n".join(summary_lines)

        nurse_options = clustered_df["nurse_id"].astype(str) + " - " + clustered_df["nurse_name"].astype(str)
        chat_nurse_label = st.selectbox(
            "ê¸°ì¤€ì´ ë  ê°„í˜¸ì‚¬ë¥¼ í•˜ë‚˜ ì„ íƒí•˜ì„¸ìš” (ë¹„êµ ì§ˆë¬¸ë„ ê°€ëŠ¥)",
            nurse_options,
            key="chat_nurse_select",
        )

        if "chat_history" not in st.session_state:
            st.session_state.chat_history = []

        if chat_nurse_label:
            chat_nurse_id = chat_nurse_label.split(" - ")[0]
            chat_nurse_row = clustered_df[clustered_df["nurse_id"].astype(str) == chat_nurse_id].iloc[0]

            # ê¸°ì¤€ ê°„í˜¸ì‚¬ ìƒì„¸
            cols_for_report = [
                "nurse_id", "nurse_name", "level_name",
                "cluster_name", "is_outlier",
                "total_working_days", "total_night_days",
                "consecutive_working_days", "consecutive_night_shifts",
                "min_off_interval_hours",
                "ED_quick_return_total", "N_quick_return_total",
                "total_off_days", "total_night_days_risk",
                "total_off_days_risk",
                "consecutive_working_days_risk",
                "consecutive_night_shifts_risk",
                "min_off_interval_risk",
                "preferred_shift_ratio", "preferred_shift_ratio_risk",
                "preferred_duty_choice_ratio", "preferred_duty_choice_risk",
                "preferred_swing_risk",
                "level_night_ratio", "level_night_ratio_risk",
                "level_workingdays_ratio", "level_workingdays_ratio_risk",
            ]

            chat_info_lines = []
            for c in cols_for_report:
                if c in chat_nurse_row.index:
                    chat_info_lines.append(f"- {c}: {chat_nurse_row[c]}")
            chat_info_text = "\n".join(chat_info_lines)

            st.markdown(f"ì„ íƒëœ ê°„í˜¸ì‚¬: **{chat_nurse_row['nurse_name']}**")

            # ê¸°ì¡´ ëŒ€í™” ì¶œë ¥
            for msg in st.session_state.chat_history:
                with st.chat_message(msg["role"]):
                    st.markdown(msg["content"])

            user_question = st.chat_input(
                "ë¶€ì„œ ì „ì²´ì— ëŒ€í•´ ë¬¼ì–´ë´ë„ ë˜ê³ , ë‘ ì‚¬ëŒ ë¹„êµë‚˜ outlier/í´ëŸ¬ìŠ¤í„° ê´€ë ¨ ì§ˆë¬¸ì„ í•˜ì…”ë„ ë©ë‹ˆë‹¤."
            )

            if user_question:
                st.session_state.chat_history.append({"role": "user", "content": user_question})

                system_prompt_chat = """
ë‹¹ì‹ ì€ ê°„í˜¸ì‚¬ ê·¼ë¬´í‘œ ë¶„ì„ ë„êµ¬ì˜ AI ì±—ë´‡ì…ë‹ˆë‹¤.
ì…ë ¥ì—ëŠ” ë¶€ì„œ ì „ì²´ ê°„í˜¸ì‚¬ë“¤ì˜ ìš”ì•½ ì •ë³´ì™€,
ì„ íƒëœ ê°„í˜¸ì‚¬ì˜ ìƒì„¸ ë¶„ì„ ê²°ê³¼ê°€ í•¨ê»˜ ì œê³µë©ë‹ˆë‹¤.

[ìœ„í—˜ë„ ë¼ë²¨ ê·œì¹™]
- risk ê°’: critical, moderate, low, no, no_preference, no_request.
- critical: ê³ ìœ„í—˜ / ì¦‰ê°ì ì¸ ê°œì„  í•„ìš”.
- moderate: ì¤‘ë“±ë„ ìœ„í—˜ / ì£¼ì˜ í•„ìš”.
- low: ê²½ë¯¸í•œ ìœ„í—˜ ë˜ëŠ” ì•½í•œ ë¶ˆê· í˜•.
- no ê³„ì—´: ì •ìƒ ë²”ìœ„, ìœ„í—˜ ìš”ì¸ ì•„ë‹˜.

[í•´ì„ ê·œì¹™]
1. ìœ„í—˜ë„ íŒë‹¨ì€ í•­ìƒ *_risk ì»¬ëŸ¼ì„ ê¸°ì¤€ìœ¼ë¡œ í•˜ì„¸ìš”.
2. riskê°€ 'no'ì¸ í•­ëª©ì„ ìœ„í—˜í•˜ë‹¤ê³  í‘œí˜„í•˜ì§€ ë§ˆì„¸ìš”.
   í•„ìš”í•˜ë©´ 'ì •ìƒ ë²”ìœ„ì…ë‹ˆë‹¤' ì •ë„ë¡œë§Œ ì„¤ëª…í•˜ì„¸ìš”.
3. ì‚¬ìš©ìê°€ 'ëˆ„ê°€ ë” í˜ë“  ìŠ¤ì¼€ì¤„ì¸ì§€', 'ëˆ„ê°€ ê°€ì¥ ìœ„í—˜í•œì§€',
   'ëˆ„ê°€ ë‚˜ì™€ íŒ¨í„´ì´ ë¹„ìŠ·í•œì§€'ë¥¼ ë¬¼ìœ¼ë©´,
   ê° ê°„í˜¸ì‚¬ì˜ *_risk ê°’ê³¼ outlier/cluster ì •ë³´ë¥¼ ë¹„êµí•´ ë‹µí•˜ì„¸ìš”.
4. ì œê³µëœ ë°ì´í„°ì— ì—†ëŠ” ì‚¬ì‹¤ì€ ì¶”ì¸¡í•˜ì§€ ë§ê³ 
   'ë°ì´í„°ì— ì—†ëŠ” ì •ë³´ì…ë‹ˆë‹¤'ë¼ê³  ë‹µí•˜ì„¸ìš”.
5. ì‚¬ìš©ìì—ê²ŒëŠ” 'critical' ë“±ì˜ ì˜ì–´ ëŒ€ì‹ 
   'ê³ ìœ„í—˜', 'ì¤‘ë“±ë„ ìœ„í—˜', 'ì €ìœ„í—˜', 'ì •ìƒ'ê³¼ ê°™ì€ í•œê¸€ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”.
6. level_name(novice/competence/leader)ì€ ê°ê°
   'ì €ì—°ì°¨', 'ì¤‘ê°„ì—°ì°¨', 'ê³ ì—°ì°¨'ë¥¼ ì˜ë¯¸í•˜ë¯€ë¡œ,
   ì„¤ëª… ì‹œ í•œêµ­ì–´ë¡œ í‘œí˜„í•˜ì„¸ìš”.

í•­ìƒ í™˜ìì•ˆì „ê³¼ ê³µì •ì„± ê´€ì ì—ì„œ ì¹œì ˆí•˜ê²Œ, í•œêµ­ì–´ ì¡´ëŒ“ë§ë¡œ ì„¤ëª…í•˜ì„¸ìš”.
"""

                base_context = f"""
[ë¶€ì„œ ì „ì²´ ê°„í˜¸ì‚¬ ìŠ¤ì¼€ì¤„ ìš”ì•½]

{all_nurses_summary}

[ì„ íƒëœ ê°„í˜¸ì‚¬ì˜ ìƒì„¸ ë¶„ì„ ê°’]

{chat_info_text}
"""

                user_prompt_chat = f"""
ìœ„ì˜ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬, ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µë³€í•´ ì£¼ì„¸ìš”.

ì§ˆë¬¸: {user_question}
"""

                with st.spinner("AIê°€ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                    chat_answer = call_llm(system_prompt_chat, base_context + "\n\n" + user_prompt_chat)

                st.session_state.chat_history.append({"role": "assistant", "content": chat_answer})

                with st.chat_message("assistant"):
                    st.markdown(chat_answer)


# ============================================================
# 3. Risk Dashboard íƒ­
# ============================================================
with tab_risk:
    st.subheader("ğŸ“Š Risk Dashboard")

    if (staffing_df is None) or (monthly_features_df is None):
        st.info("Risk Dashboardë¥¼ ë³´ë ¤ë©´ **Schedule íƒ­ì—ì„œ ê·¼ë¬´í‘œë¥¼ ì—…ë¡œë“œ**í•´ ì£¼ì„¸ìš”.")
    else:
        # -------------------------
        # 3-1. ë‚ ì§œë³„ ì¸ë ¥ ê¸°ì¤€ ì¶©ì¡± ì—¬ë¶€ (ê¸°ì¡´ ê·¸ëŒ€ë¡œ)
        # -------------------------
        st.markdown("### ğŸ“ˆ ë‚ ì§œë³„ ì¸ë ¥ ê¸°ì¤€ ì¶©ì¡± ì—¬ë¶€")

        plot_df = staffing_df.copy()
        plot_df["overall_risk_score"] = plot_df["overall_staffing_risk"].map(RISK_SCORE)

        chart = (
            alt.Chart(plot_df)
            .mark_line(point=True)
            .encode(
                x=alt.X("date:T", title="ë‚ ì§œ"),
                y=alt.Y(
                    "overall_risk_score:Q",
                    title="ìœ„í—˜ë„ ìˆ˜ì¤€",
                    scale=alt.Scale(domain=[0, 3]),
                    axis=alt.Axis(
                        values=[0, 1, 2, 3],
                        labelExpr="datum.value == 0 ? 'no' : datum.value == 1 ? 'low' : datum.value == 2 ? 'moderate' : 'critical'"
                    ),
                ),
                tooltip=[
                    alt.Tooltip("date:T", title="ë‚ ì§œ"),
                    alt.Tooltip("overall_staffing_risk:N", title="ìµœê³  ìœ„í—˜ë„"),
                ],
            )
        )

        st.altair_chart(chart, use_container_width=True)

        # ë‚ ì§œ ì„ íƒí•´ì„œ ìƒì„¸ í…ìŠ¤íŠ¸ ë³´ì—¬ì£¼ê¸°
        try:
            date_options = plot_df["date"].dt.date.astype(str).tolist()
        except Exception:
            date_options = plot_df["date"].astype(str).tolist()

        selected_date_str = st.selectbox("ìƒì„¸ ì¸ë ¥ ì •ë³´ë¥¼ ë³¼ ë‚ ì§œë¥¼ ì„ íƒí•˜ì„¸ìš”", date_options)
        day_row = plot_df[plot_df["date"].astype(str).str.contains(selected_date_str)].iloc[0]

        st.markdown(f"**[{selected_date_str}] ì¸ë ¥ ê¸°ì¤€ ìƒì„¸**")

        for code, label in SHIFT_MAP.items():
            risk = day_row.get(f"{label}_risk", "no")
            shortage = int(day_row.get(f"{label}_shortage", 0))
            if risk == "no":
                text = "ê¸°ì¤€ ì¶©ì¡±"
            else:
                text = f"{risk_to_ko(risk)} / {shortage}ëª… ë¶€ì¡±"
            st.write(f"- {label}: {text}")

        st.write("---")

        # -------------------------
        # 3-2. í™˜ì ì•ˆì „ ìœ„í—˜ë„ (ê°œì¸ ê¸°ì¤€) â€“ ì°¸ê³  ì½”ë“œ ë²„ì „
        # -------------------------
        st.subheader("ğŸ›¡ï¸ í™˜ì ì•ˆì „ ìœ„í—˜ë„ (ê°œì¸ ê¸°ì¤€)")

        cols = [
            "nurse_id",
            "nurse_name",
            "level",
            "ED_quick_return_risk",
            "N_quick_return_risk",
            "consecutive_working_days",
            "consecutive_working_days_risk",
            "consecutive_night_shifts",
            "consecutive_night_shifts_risk",
        ]
        risk_df = monthly_features_df[cols].copy()

        risk_df["ì—°ì°¨"] = risk_df["level"].map(LEVEL_KO)
        risk_df["Eâ†’D íŒŒí–‰ê·¼ë¬´ ìœ„í—˜ë„"] = risk_df["ED_quick_return_risk"].apply(risk_to_ko)
        risk_df["N íŒŒí–‰ê·¼ë¬´ ìœ„í—˜ë„"] = risk_df["N_quick_return_risk"].apply(risk_to_ko)
        risk_df["ì—°ì† ê·¼ë¬´ ì¼ ìˆ˜"] = risk_df["consecutive_working_days"]
        risk_df["ì—°ì† ê·¼ë¬´ ìœ„í—˜ë„"] = risk_df["consecutive_working_days_risk"].apply(
            risk_to_ko
        )
        risk_df["ì—°ì† Nê·¼ë¬´ ì¼ ìˆ˜"] = risk_df["consecutive_night_shifts"]
        risk_df["ì—°ì† Nê·¼ë¬´ ìœ„í—˜ë„"] = risk_df["consecutive_night_shifts_risk"].apply(
            risk_to_ko
        )

        display_cols = [
            "nurse_id",
            "nurse_name",
            "ì—°ì°¨",
            "Eâ†’D íŒŒí–‰ê·¼ë¬´ ìœ„í—˜ë„",
            "N íŒŒí–‰ê·¼ë¬´ ìœ„í—˜ë„",
            "ì—°ì† ê·¼ë¬´ ì¼ ìˆ˜",
            "ì—°ì† ê·¼ë¬´ ìœ„í—˜ë„",
            "ì—°ì† Nê·¼ë¬´ ì¼ ìˆ˜",
            "ì—°ì† Nê·¼ë¬´ ìœ„í—˜ë„",
        ]
        st.dataframe(risk_df[display_cols], use_container_width=True)

        st.markdown("#### ğŸ“Š ì—°ì† ê·¼ë¬´/ì—°ì† Nê·¼ë¬´ ë¶„í¬ (ë§‰ëŒ€ê·¸ë˜í”„)")

        bar_df = risk_df[["nurse_name", "ì—°ì† ê·¼ë¬´ ì¼ ìˆ˜", "ì—°ì† Nê·¼ë¬´ ì¼ ìˆ˜"]].set_index(
            "nurse_name"
        )
        st.bar_chart(bar_df)

        # -------------------------
        # 3-3. ìœ„í—˜ë„ Heatmap (ê°€ë¡œì¶• í•œê¸€ë¡œ)
        # -------------------------
        st.markdown("#### ğŸ”¥ ìœ„í—˜ë„ Heatmap")

        heat_df = monthly_features_df[
            ["nurse_id", "nurse_name",
             "ED_quick_return_risk", "N_quick_return_risk",
             "consecutive_working_days_risk", "consecutive_night_shifts_risk"]
        ].copy()

        heat_df = heat_df.rename(columns={"nurse_id": "ID", "nurse_name": "ê°„í˜¸ì‚¬"})
        heat_long = heat_df.melt(
            id_vars=["ID", "ê°„í˜¸ì‚¬"],
            var_name="ì§€í‘œ",
            value_name="risk",
        )

        # ì§€í‘œ ì´ë¦„ì„ í•œê¸€ë¡œ ë§¤í•‘
        label_map = {
            "ED_quick_return_risk": "Eâ†’D íŒŒí–‰ê·¼ë¬´ ìœ„í—˜ë„",
            "N_quick_return_risk": "N íŒŒí–‰ê·¼ë¬´ ìœ„í—˜ë„",
            "consecutive_working_days_risk": "ì—°ì† ê·¼ë¬´ ìœ„í—˜ë„",
            "consecutive_night_shifts_risk": "ì—°ì† Nê·¼ë¬´ ìœ„í—˜ë„",
        }
        heat_long["ì§€í‘œ"] = heat_long["ì§€í‘œ"].map(label_map).fillna(heat_long["ì§€í‘œ"])

        heat_long["risk_score"] = heat_long["risk"].map(RISK_SCORE)

        heat_chart = (
            alt.Chart(heat_long)
            .mark_rect()
            .encode(
                x=alt.X("ì§€í‘œ:N", title="ì§€í‘œ"),
                y=alt.Y("ê°„í˜¸ì‚¬:N", title="ê°„í˜¸ì‚¬"),
                color=alt.Color(
                    "risk_score:Q",
                    scale=alt.Scale(domain=[0, 3], range=["#e0f7fa", "#80deea", "#ffb74d", "#e53935"]),
                    legend=alt.Legend(title="ìœ„í—˜ë„(0~3)"),
                ),
                tooltip=["ID", "ê°„í˜¸ì‚¬", "ì§€í‘œ", "risk"],
            )
        )

        st.altair_chart(heat_chart, use_container_width=True)
        # (ìš”ì²­ì— ë”°ë¼ Eâ†’D/N íŒŒí–‰ê·¼ë¬´ ê°œë³„ ê·¸ë˜í”„ëŠ” ì‚­ì œ)


# ============================================================
# 4. Fairness Dashboard íƒ­ (ì°¸ê³  ì½”ë“œ ë²„ì „ ê·¸ëŒ€ë¡œ)
# ============================================================
with tab_fairness:
    st.subheader("âš–ï¸ ê³µì •ì„± ëŒ€ì‹œë³´ë“œ")

    if clustered_df is None:
        st.info("ê³µì •ì„± ë¶„ì„ì„ ë³´ë ¤ë©´ **Schedule íƒ­ì—ì„œ ì„ í˜¸ê·¼ë¬´í‘œê¹Œì§€ ì—…ë¡œë“œ**í•´ ì£¼ì„¸ìš”.")
    else:
        # 1) ê³µì •ì„± ë¹„êµí‘œ
        st.markdown("### 1) ê³µì •ì„± ë¹„êµí‘œ")

        fair_cols = [
            "nurse_id",
            "nurse_name",
            "level",
            "preferred_shift_ratio",
            "preferred_shift_ratio_risk",
            "preferred_duty_choice_ratio",
            "preferred_duty_choice_risk",
            "preferred_swing_risk",
            "level_workingdays_ratio",
            "level_workingdays_ratio_risk",
            "level_night_ratio",
            "level_night_ratio_risk",
            "total_working_days",
            "total_off_days",
            "total_off_days_risk",
            "total_night_days",
            "total_night_days_risk",
            "min_off_interval_risk",
            "preferred_shift_total",
            "preferred_shift_matched",
            "preferred_duty_requests",
            "preferred_duty_matched",
        ]

        fair_df = clustered_df[fair_cols].copy()

        # ratioë¥¼ "ë¶„ìˆ˜" í˜•íƒœë¡œ í‘œí˜„
        def shift_ratio_str(row):
            total = row["preferred_shift_total"]
            matched = row["preferred_shift_matched"]
            if pd.isna(total) or total == 0:
                return "-"
            return f"{int(matched)}/{int(total)}"

        def duty_ratio_str(row):
            total = row["preferred_duty_requests"]
            matched = row["preferred_duty_matched"]
            if total == 0:
                return "-"
            return f"{int(matched)}/{int(total)}"

        fair_df["preferred_shift_ratio"] = fair_df.apply(shift_ratio_str, axis=1)
        fair_df["preferred_duty_choice_ratio"] = fair_df.apply(
            duty_ratio_str, axis=1
        )

        fair_df["ì—°ì°¨"] = fair_df["level"].map(LEVEL_KO)
        fair_df["í¬ë§ê·¼ë¬´ ë°˜ì˜ìœ¨"] = fair_df["preferred_shift_ratio"]
        fair_df["í¬ë§ê·¼ë¬´ ë°˜ì˜ ìœ„í—˜ë„"] = fair_df["preferred_shift_ratio_risk"].apply(
            risk_to_ko
        )
        fair_df["ì„ í˜¸ê·¼íƒœ ë°˜ì˜ìœ¨"] = fair_df["preferred_duty_choice_ratio"]
        fair_df["ì„ í˜¸ê·¼íƒœ ë°˜ì˜ ìœ„í—˜ë„"] = fair_df[
            "preferred_duty_choice_risk"
        ].apply(risk_to_ko)
        fair_df["í˜¼í•©êµëŒ€ ì„ í˜¸ ë°˜ì˜ ìœ„í—˜ë„"] = fair_df["preferred_swing_risk"].apply(
            risk_to_ko
        )
        fair_df["ì—°ì°¨ ëŒ€ë¹„ ê·¼ë¬´ì¼ìˆ˜ ë¹„ìœ¨"] = fair_df["level_workingdays_ratio"]
        fair_df["ì—°ì°¨ ëŒ€ë¹„ ê·¼ë¬´ì¼ìˆ˜ ìœ„í—˜ë„"] = fair_df[
            "level_workingdays_ratio_risk"
        ].apply(risk_to_ko)
        fair_df["ì—°ì°¨ ëŒ€ë¹„ Nê·¼ë¬´ ë¹„ìœ¨"] = fair_df["level_night_ratio"]
        fair_df["ì—°ì°¨ ëŒ€ë¹„ Nê·¼ë¬´ ìœ„í—˜ë„"] = fair_df["level_night_ratio_risk"].apply(
            risk_to_ko
        )
        fair_df["ì´ ê·¼ë¬´ì¼ìˆ˜"] = fair_df["total_working_days"]
        fair_df["ì´ OFF ì¼ìˆ˜"] = fair_df["total_off_days"]
        fair_df["ì´ OFF ìœ„í—˜ë„"] = fair_df["total_off_days_risk"].apply(risk_to_ko)
        fair_df["ì´ Nê·¼ë¬´ ì¼ìˆ˜"] = fair_df["total_night_days"]
        fair_df["ì´ Nê·¼ë¬´ ìœ„í—˜ë„"] = fair_df["total_night_days_risk"].apply(risk_to_ko)
        fair_df["ìµœì†Œ íœ´ì‹ì‹œê°„ ìœ„í—˜ë„"] = fair_df["min_off_interval_risk"].apply(
            risk_to_ko
        )

        display_cols = [
            "nurse_id",
            "nurse_name",
            "ì—°ì°¨",
            "í¬ë§ê·¼ë¬´ ë°˜ì˜ìœ¨",
            "í¬ë§ê·¼ë¬´ ë°˜ì˜ ìœ„í—˜ë„",
            "ì„ í˜¸ê·¼íƒœ ë°˜ì˜ìœ¨",
            "ì„ í˜¸ê·¼íƒœ ë°˜ì˜ ìœ„í—˜ë„",
            "í˜¼í•©êµëŒ€ ì„ í˜¸ ë°˜ì˜ ìœ„í—˜ë„",
            "ì—°ì°¨ ëŒ€ë¹„ ê·¼ë¬´ì¼ìˆ˜ ë¹„ìœ¨",
            "ì—°ì°¨ ëŒ€ë¹„ ê·¼ë¬´ì¼ìˆ˜ ìœ„í—˜ë„",
            "ì—°ì°¨ ëŒ€ë¹„ Nê·¼ë¬´ ë¹„ìœ¨",
            "ì—°ì°¨ ëŒ€ë¹„ Nê·¼ë¬´ ìœ„í—˜ë„",
            "ì´ ê·¼ë¬´ì¼ìˆ˜",
            "ì´ OFF ì¼ìˆ˜",
            "ì´ OFF ìœ„í—˜ë„",
            "ì´ Nê·¼ë¬´ ì¼ìˆ˜",
            "ì´ Nê·¼ë¬´ ìœ„í—˜ë„",
            "ìµœì†Œ íœ´ì‹ì‹œê°„ ìœ„í—˜ë„",
        ]
        st.dataframe(fair_df[display_cols], use_container_width=True)

        st.write("---")
        st.markdown("### 2) ê°œë³„ ê°„í˜¸ì‚¬ ê³µì •ì„± ë¶„ì„")

        nurse_options = fair_df["nurse_id"].astype(str) + " - " + fair_df["nurse_name"]
        selected_label = st.selectbox(
            "ë¶„ì„í•  ê°„í˜¸ì‚¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”", nurse_options
        )
        selected_id = selected_label.split(" - ")[0]
        row = fair_df[fair_df["nurse_id"].astype(str) == selected_id].iloc[0]
        raw_row = clustered_df[clustered_df["nurse_id"].astype(str) == selected_id].iloc[0]

        st.markdown(f"#### ğŸ‘©â€âš•ï¸ {row['nurse_name']} ê°„í˜¸ì‚¬ ê³µì •ì„± ë¶„ì„")

        # â—† ì„ í˜¸ ë°˜ì˜ìœ¨
        st.markdown("**â—† ì„ í˜¸ ë°˜ì˜ìœ¨**")

        # í¬ë§ê·¼ë¬´
        pref_shift_type = raw_row.get("preferred_shift_type_code", math.nan)
        shift_matched = int(raw_row.get("preferred_shift_matched", 0))
        shift_total = int(raw_row.get("preferred_shift_total", 0))
        if pd.isna(pref_shift_type) or shift_total == 0:
            txt_shift = "Â· í¬ë§ê·¼ë¬´ë¥¼ ë³„ë„ë¡œ ì‹ ì²­í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        else:
            shift_code = int(pref_shift_type)
            shift_name = SHIFT_MAP.get(shift_code, str(shift_code))
            txt_shift = (
                f"Â· í¬ë§ê·¼ë¬´ ë°˜ì˜ìœ¨: {shift_total}ì¼ ì¤‘ {shift_matched}ì¼ "
                f"(ì£¼ë¡œ {shift_name} ê·¼ë¬´ë¥¼ ì„ í˜¸)"
            )

        # ì„ í˜¸ê·¼íƒœ
        duty_req = int(raw_row.get("preferred_duty_requests", 0))
        duty_match = int(raw_row.get("preferred_duty_matched", 0))
        if duty_req == 0:
            txt_duty = "Â· ì„ í˜¸ê·¼íƒœë¥¼ ë³„ë„ë¡œ ì‹ ì²­í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        else:
            txt_duty = f"Â· ì„ í˜¸ê·¼íƒœ ë°˜ì˜ìœ¨: {duty_req}ì¼ ì¤‘ {duty_match}ì¼"

        # í˜¼í•©êµëŒ€
        swing_flag = bool(raw_row.get("preferred_swing_flag", False))
        swing_risk = raw_row.get("preferred_swing_risk", "no")
        if not swing_flag:
            txt_swing = "Â· í˜¼í•©êµëŒ€ë¥¼ íŠ¹ë³„íˆ ì„ í˜¸í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
        else:
            if swing_risk == "no":
                txt_swing = "Â· í˜¼í•©êµëŒ€ ì„ í˜¸ ë°˜ì˜: ì„ í˜¸ê°€ ëŒ€ë¶€ë¶„ ë°˜ì˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
            else:
                txt_swing = "Â· í˜¼í•©êµëŒ€ ì„ í˜¸ ë°˜ì˜: ì„ í˜¸ê°€ ì¶©ë¶„íˆ ë°˜ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

        st.markdown("\n".join([txt_shift, txt_duty, txt_swing]))

        # â—† ì—°ì°¨ ê¸°ë°˜ ê³µì •ì„±
        st.markdown("**â—† ì—°ì°¨ ê¸°ë°˜ ê³µì •ì„±**")

        def mag_from_risk(r):
            if r == "critical":
                return "ë§¤ìš° ë§ìŒ"
            elif r == "moderate":
                return "ë§ìŒ"
            elif r == "low":
                return "ì•½ê°„ ë§ìŒ"
            else:
                return "ë¹„ìŠ·í•˜ê±°ë‚˜ ì ìŒ"

        night_ratio_risk = raw_row.get("level_night_ratio_risk", "no")
        work_ratio_risk = raw_row.get("level_workingdays_ratio_risk", "no")

        txt_night = (
            "Â· ë‹¤ë¥¸ ì—°ì°¨êµ°ê³¼ ë¹„êµí–ˆì„ ë•Œ N ê·¼ë¬´ ì¼ ìˆ˜ê°€ "
            f"{mag_from_risk(night_ratio_risk)} ìˆ˜ì¤€ì…ë‹ˆë‹¤."
        )
        txt_work = (
            "Â· ë‹¤ë¥¸ ì—°ì°¨êµ°ê³¼ ë¹„êµí–ˆì„ ë•Œ ì „ì²´ ê·¼ë¬´ ì¼ ìˆ˜ê°€ "
            f"{mag_from_risk(work_ratio_risk)} ìˆ˜ì¤€ì…ë‹ˆë‹¤."
        )
        st.markdown("\n".join([txt_night, txt_work]))

        # â—† OFF / N / Interval
        st.markdown("**â—† OFF / N / Interval**")

        off_days = int(raw_row.get("total_off_days", 0))
        off_risk = raw_row.get("total_off_days_risk", "no")
        night_days = int(raw_row.get("total_night_days", 0))
        night_days_risk = raw_row.get("total_night_days_risk", "no")
        min_interval = raw_row.get("min_off_interval_hours", None)
        min_interval_risk = raw_row.get("min_off_interval_risk", "no")

        txt_off = f"Â· ì´ OFF ì¼ ìˆ˜: {off_days}ì¼ â€“ {risk_to_ko(off_risk)}"
        txt_night_days = f"Â· ì´ N ê·¼ë¬´ ì¼ ìˆ˜: {night_days}ì¼ â€“ {risk_to_ko(night_days_risk)}"
        if min_interval is None or (isinstance(min_interval, float) and math.isnan(min_interval)):
            txt_int = "Â· ê·¼ë¬´ ê°„ ìµœì†Œ íœ´ì‹ ì‹œê°„: ê³„ì‚° ë¶ˆê°€(ê·¼ë¬´ íŒ¨í„´ì´ ì¶©ë¶„í•˜ì§€ ì•ŠìŒ)"
        else:
            txt_int = (
                f"Â· ê·¼ë¬´ ê°„ ìµœì†Œ íœ´ì‹ ì‹œê°„: {round(float(min_interval), 1)}ì‹œê°„ â€“ "
                f"{risk_to_ko(min_interval_risk)}"
            )

        st.markdown("\n".join([txt_off, txt_night_days, txt_int]))


# ============================================================
# 5. AI Report íƒ­ (í´ëŸ¬ìŠ¤í„°ë§+outlier ì„¤ëª… ì¶”ê°€)
# ============================================================
with tab_report:
    if clustered_df is None:
        st.subheader("ğŸ§  AI ê¸°ë°˜ ìŠ¤ì¼€ì¤„ í•´ì„ ë¦¬í¬íŠ¸")
        st.info("AI ë¦¬í¬íŠ¸ë¥¼ ë³´ë ¤ë©´ **Schedule íƒ­ì—ì„œ ì„ í˜¸ê·¼ë¬´í‘œê¹Œì§€ ì—…ë¡œë“œ**í•´ ì£¼ì„¸ìš”.")
    else:
        # -------------------------
        # 5-1. í´ëŸ¬ìŠ¤í„°ë§ê³¼ outlier ë‹¤ì´ì–´ê·¸ë¨ + ì„¤ëª…
        # -------------------------
        st.markdown("### í´ëŸ¬ìŠ¤í„°ë§ê³¼ outlier")

        # ë‹¤ì´ì–´ê·¸ë¨: Clusterë³„ ê°„í˜¸ì‚¬ ì´ë¦„ ë‚˜ì—´
        cluster_names = sorted(clustered_df["cluster_name"].unique())
        diag_lines = ["```"]
        for cname in cluster_names:
            names = clustered_df[clustered_df["cluster_name"] == cname]["nurse_name"].tolist()
            diag_lines.append(f"{cname}:")
            if names:
                for n in names:
                    diag_lines.append(f"  - {n}")
            else:
                diag_lines.append("  (ê°„í˜¸ì‚¬ ì—†ìŒ)")
            diag_lines.append("")
        diag_lines.append("```")
        st.markdown("\n".join(diag_lines))

        # ê°„ë‹¨í•œ íŠ¹ì„± ì„¤ëª… (ì´ ê·¼ë¬´ì¼ìˆ˜ / N ê·¼ë¬´ ê¸°ì¤€ìœ¼ë¡œ)
        metric_cols = [c for c in ["total_working_days", "total_night_days"] if c in clustered_df.columns]
        explanation_lines = []
        if metric_cols:
            overall_mean = clustered_df[metric_cols].mean()

            def compare_word(val, overall):
                if pd.isna(val) or pd.isna(overall):
                    return "ë¹„ìŠ·í•œ"
                diff = val - overall
                if diff > 1:
                    return "ë” ë§ì€"
                elif diff < -1:
                    return "ë” ì ì€"
                else:
                    return "ë¹„ìŠ·í•œ"

            for cname in cluster_names:
                sub = clustered_df[clustered_df["cluster_name"] == cname]
                means = sub[metric_cols].mean()
                if "total_working_days" in metric_cols:
                    w_phrase = compare_word(means["total_working_days"], overall_mean["total_working_days"])
                else:
                    w_phrase = "ë¹„ìŠ·í•œ"
                if "total_night_days" in metric_cols:
                    n_phrase = compare_word(means["total_night_days"], overall_mean["total_night_days"])
                else:
                    n_phrase = "ë¹„ìŠ·í•œ"

                explanation_lines.append(
                    f"- **{cname}**: ì „ì²´ í‰ê· ê³¼ ë¹„êµí–ˆì„ ë•Œ ì´ ê·¼ë¬´ì¼ ìˆ˜ê°€ {w_phrase} í¸ì´ê³ , "
                    f"N ê·¼ë¬´ íšŸìˆ˜ê°€ {n_phrase} í¸ì¸ ê°„í˜¸ì‚¬ë“¤ì´ ëª¨ì—¬ ìˆìŠµë‹ˆë‹¤."
                )

        out_df = clustered_df[clustered_df["is_outlier"] == "outlier"]
        if len(out_df) > 0:
            out_names = ", ".join(out_df["nurse_name"].astype(str).tolist())
            out_text = (
                f"\n\nì´ìƒì¹˜(outlier)ë¡œ ë¶„ë¥˜ëœ ê°„í˜¸ì‚¬ëŠ” **{out_names}** ì…ë‹ˆë‹¤. "
                "ì´ ê°„í˜¸ì‚¬ë“¤ì€ ì´ ê·¼ë¬´ì¼ ìˆ˜, ì•¼ê°„ ê·¼ë¬´, quick return, OFF ì¼ìˆ˜ ë“±ì—ì„œ "
                "ë‹¤ë¥¸ ê°„í˜¸ì‚¬ ê·¸ë£¹ê³¼ ë¹„êµí–ˆì„ ë•Œ ìƒëŒ€ì ìœ¼ë¡œ í¬ê²Œ ë²—ì–´ë‚œ íŒ¨í„´ì„ ë³´ì—¬ "
                "ìŠ¤ì¼€ì¤„ ì¡°ì •ì´ë‚˜ ì¶”ê°€ì ì¸ ì§€ì›ì´ í•„ìš”í•œì§€ ê²€í† í•´ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            )
        else:
            out_text = (
                "\n\ní˜„ì¬ ì„¤ì •ëœ ê¸°ì¤€(IsolationForest)ì— ë”°ë¼ ì´ìƒì¹˜(outlier)ë¡œ ë¶„ë¥˜ëœ ê°„í˜¸ì‚¬ëŠ” ì—†ìŠµë‹ˆë‹¤."
            )

        st.markdown(
            "í´ëŸ¬ìŠ¤í„°ëŠ” ì´ ê·¼ë¬´ì¼ ìˆ˜, N ê·¼ë¬´ íšŸìˆ˜, quick return ë°œìƒ, "
            "ì„ í˜¸ê·¼ë¬´ ë°˜ì˜ë¥  ë“±ì˜ íŒ¨í„´ì´ ë¹„ìŠ·í•œ ê°„í˜¸ì‚¬ë“¤ì„ í•˜ë‚˜ì˜ ê·¸ë£¹ìœ¼ë¡œ ë¬¶ì€ ê²ƒì…ë‹ˆë‹¤.\n\n"
            + ("\n".join(explanation_lines) if explanation_lines else "")
            + out_text
        )

        st.write("---")

        # -------------------------
        # 5-2. ê¸°ì¡´ AI ê¸°ë°˜ ìŠ¤ì¼€ì¤„ í•´ì„ ë¦¬í¬íŠ¸
        # -------------------------
        st.subheader("ğŸ§  AI ê¸°ë°˜ ìŠ¤ì¼€ì¤„ í•´ì„ ë¦¬í¬íŠ¸")

        nurse_options = clustered_df["nurse_id"].astype(str) + " - " + clustered_df["nurse_name"].astype(str)
        selected_label = st.selectbox(
            "ë¦¬í¬íŠ¸ë¥¼ ë³´ê³  ì‹¶ì€ ê°„í˜¸ì‚¬ë¥¼ ì„ íƒí•˜ì„¸ìš”", nurse_options
        )

        cols_for_report = [
            "nurse_id", "nurse_name", "level_name",
            "cluster_name", "is_outlier",
            "total_working_days", "total_night_days",
            "consecutive_working_days", "consecutive_night_shifts",
            "min_off_interval_hours",
            "ED_quick_return_total", "N_quick_return_total",
            "total_off_days", "total_night_days_risk",
            "total_off_days_risk",
            "consecutive_working_days_risk",
            "consecutive_night_shifts_risk",
            "min_off_interval_risk",
            "preferred_shift_ratio", "preferred_shift_ratio_risk",
            "preferred_duty_choice_ratio", "preferred_duty_choice_risk",
            "preferred_swing_risk",
            "level_night_ratio", "level_night_ratio_risk",
            "level_workingdays_ratio", "level_workingdays_ratio_risk",
        ]

        if selected_label:
            selected_id = selected_label.split(" - ")[0]
            nurse_row = clustered_df[clustered_df["nurse_id"].astype(str) == selected_id].iloc[0]

            if st.button("ì´ ê°„í˜¸ì‚¬ì˜ AI ë¦¬í¬íŠ¸ ìƒì„±í•˜ê¸°"):
                info_lines = []
                for c in cols_for_report:
                    if c in nurse_row.index:
                        info_lines.append(f"- {c}: {nurse_row[c]}")
                info_text = "\n".join(info_lines)

                system_prompt = """
ë‹¹ì‹ ì€ ê°„í˜¸ì‚¬ ê·¼ë¬´ ìŠ¤ì¼€ì¤„ ë¶„ì„ì„ ë•ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì…ë ¥ìœ¼ë¡œëŠ” ê° ê°„í˜¸ì‚¬ë³„ ë‹¤ì–‘í•œ ìˆ˜ì¹˜ ì§€í‘œì™€ í•¨ê»˜,
ê° ì§€í‘œì— ëŒ€í•œ ìœ„í—˜ë„ ë¼ë²¨(*_risk)ì´ í•¨ê»˜ ì œê³µë©ë‹ˆë‹¤.

[ìœ„í—˜ë„ ë¼ë²¨ ê·œì¹™]
- risk ê°’: critical, moderate, low, no, no_preference, no_request.
- critical: ê³ ìœ„í—˜, ì¦‰ê°ì ì¸ ê°œì„ ì´ í•„ìš”í•¨.
- moderate: ì¤‘ë“±ë„ ìœ„í—˜, ì£¼ì˜ ê¹Šì€ ëª¨ë‹ˆí„°ë§ê³¼ ì¡°ì •ì´ í•„ìš”í•¨.
- low: ê²½ë¯¸í•œ ìœ„í—˜ ë˜ëŠ” ì•½í•œ ë¶ˆê· í˜•(ì°¸ê³  ìˆ˜ì¤€).
- no / no_preference / no_request: ì •ìƒ ë²”ìœ„ì´ë©° ìœ„í—˜ ìš”ì¸ìœ¼ë¡œ ì·¨ê¸‰í•˜ì§€ ì•ŠìŒ.

[í•´ì„ ê·œì¹™ â€“ ë§¤ìš° ì¤‘ìš”]
1. 'í™˜ìì•ˆì „ ê´€ì  ì£¼ìš” ìœ„í—˜ ìš”ì¸'ì—ëŠ” critical / moderate ìˆ˜ì¤€ë§Œ í¬í•¨í•˜ì‹­ì‹œì˜¤.
   lowë‚˜ noì¸ ì§€í‘œëŠ” ì—¬ê¸°ì— ë„£ì§€ ë§ˆì„¸ìš”.
2. 'no'ì¸ ì§€í‘œëŠ” 'ì •ìƒ ë²”ìœ„'ë¼ê³ ë§Œ ê°„ë‹¨íˆ ì–¸ê¸‰í•˜ê±°ë‚˜, í•„ìš” ì—†ìœ¼ë©´ ìƒëµí•´ë„ ë©ë‹ˆë‹¤.
3. ì—°ì†ê·¼ë¬´ì¼ìˆ˜, ì•¼ê°„ê·¼ë¬´ì¼ìˆ˜ ë“± ìˆ˜ì¹˜ëŠ” ë°˜ë“œì‹œ ëŒ€ì‘í•˜ëŠ” *_risk ê°’ê³¼ í•¨ê»˜ í•´ì„í•´ì•¼ í•©ë‹ˆë‹¤.
4. ê³µì •ì„± ê´€ë ¨ ì§€í‘œ(level_*_ratio_risk, preferred_*_risk ë“±)ëŠ”
   'ê³µì •ì„±/í˜•í‰ì„± ê´€ì  ì£¼ìš” ì´ìŠˆ'ì—ì„œ ë‹¤ë£¨ê³ , critical / moderate ìœ„ì£¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.
5. ì‚¬ìš©ìì—ê²Œ ì„¤ëª…í•  ë•Œ 'critical' ê°™ì€ ì˜ì–´ë¥¼ ê·¸ëŒ€ë¡œ ì“°ì§€ ë§ê³ 
   'ê³ ìœ„í—˜', 'ì¤‘ë“±ë„ ìœ„í—˜', 'ì €ìœ„í—˜', 'ì •ìƒ'ê³¼ ê°™ì´ í•œê¸€ë¡œ í‘œí˜„í•˜ì‹­ì‹œì˜¤.
6. level_name(novice/competence/leader)ì€ ê°ê°
   'ì €ì—°ì°¨', 'ì¤‘ê°„ì—°ì°¨', 'ê³ ì—°ì°¨'ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. ì„¤ëª… ì‹œ í•œêµ­ì–´ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”.

[ì§€í‘œ ì˜ë¯¸(ê°„ëµ)]
- total_off_days_risk: í•œ ë‹¬ OFF ì¼ìˆ˜ê°€ ì ì ˆí•œì§€(ë„ˆë¬´ ì ìœ¼ë©´ ìœ„í—˜).
- total_night_days_risk: í•œ ë‹¬ ì•¼ê°„ ê·¼ë¬´ì¼ìˆ˜ì˜ ë¶€ë‹´ ì •ë„.
- consecutive_working_days_risk: ì—°ì† ê·¼ë¬´ ì¼ìˆ˜ì˜ ê³¼ë„ ì—¬ë¶€.
- consecutive_night_shifts_risk: ì—°ì† ì•¼ê°„ ê·¼ë¬´ ê³¼ë„ ì—¬ë¶€.
- min_off_interval_risk: ê·¼ë¬´ ì‚¬ì´ ìµœì†Œ íœ´ì‹ ì‹œê°„ ìœ„ë°˜ ì—¬ë¶€.
- ED_quick_return_risk / N_quick_return_risk:
  êµëŒ€ ê°„ ê°„ê²©ì´ ë„ˆë¬´ ì§§ì€ quick return íŒ¨í„´ì˜ ìœ„í—˜.

[ë‹µë³€ í˜•ì‹]
1) í™˜ìì•ˆì „ ê´€ì  ì£¼ìš” ìœ„í—˜ ìš”ì¸ (critical / moderateë§Œ)
2) ê³µì •ì„±/í˜•í‰ì„± ê´€ì  ì£¼ìš” ì´ìŠˆ
3) ìŠ¤ì¼€ì¤„ ì¡°ì • ì‹œì‚¬ì  (ì•¼ê°„/ì—°ì†ê·¼ë¬´ ì¡°ì •, ì„ í˜¸ê·¼ë¬´ ë°˜ì˜ ë“±)

í•œêµ­ì–´ ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•˜ê³ , 5~10ë¬¸ì¥ ì •ë„ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.
"""

                user_prompt = f"""
ë‹¤ìŒì€ í•œ ê°„í˜¸ì‚¬ì˜ ê·¼ë¬´ ìŠ¤ì¼€ì¤„ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤.

{info_text}

ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ,
1) í™˜ìì•ˆì „ ê´€ì  ì£¼ìš” ìœ„í—˜ ìš”ì¸
2) ê³µì •ì„±/í˜•í‰ì„± ê´€ì  ì£¼ìš” ì´ìŠˆ
3) ìŠ¤ì¼€ì¤„ ì¡°ì • ì‹œì‚¬ì 

ì„ í•­ëª©í˜• ìš”ì•½ + ì§§ì€ ì„¤ëª…ìœ¼ë¡œ ì •ë¦¬í•´ ì£¼ì„¸ìš”.
"""

                with st.spinner("AIê°€ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                    answer = call_llm(system_prompt, user_prompt)

                st.markdown(answer)
